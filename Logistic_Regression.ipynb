{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "colab": {
      "name": "Logistic Regression.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/treyra/CS155_miniproject/blob/master/Logistic_Regression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5aZrJLBWB8N0"
      },
      "source": [
        "\r\n",
        "# This notebook creates a simple logistic regression model on the data to experiment with different features and different normilizations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "VO6T8OgVB8N6"
      },
      "source": [
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import roc_auc_score\n",
        "import pandas as pd"
      ],
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6STW31z5B8N7"
      },
      "source": [
        "### Load the data:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AFaY9ZYBB8N7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "2c8cd1c8-67eb-43f2-ebc1-09f90e9c8af4"
      },
      "source": [
        "#Use the imputed and normalized data (This link will need to be updated when we merge the branches)\n",
        "dfImp = pd.read_csv('https://raw.githubusercontent.com/treyra/CS155_miniproject/data_visualization_v1/data_cleanup/traindata_imputed_normalized_minmax.csv',sep=',', header=0,index_col=0)\n",
        "\n",
        "dfImp.head()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>LATITUDE</th>\n",
              "      <th>LONGITUDE</th>\n",
              "      <th>STATE</th>\n",
              "      <th>DISCOVERY_TIME</th>\n",
              "      <th>FIRE_SIZE</th>\n",
              "      <th>FIPS_NAME</th>\n",
              "      <th>FIPS_CODE</th>\n",
              "      <th>SOURCE_REPORTING_UNIT_NAME</th>\n",
              "      <th>YEAR</th>\n",
              "      <th>DAY</th>\n",
              "      <th>LABEL</th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0.988292</td>\n",
              "      <td>-0.985738</td>\n",
              "      <td>1</td>\n",
              "      <td>0.054167</td>\n",
              "      <td>-0.026526</td>\n",
              "      <td>1.048773</td>\n",
              "      <td>-1.143120</td>\n",
              "      <td>-0.871063</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.002732</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>-0.401537</td>\n",
              "      <td>0.925104</td>\n",
              "      <td>0</td>\n",
              "      <td>0.464583</td>\n",
              "      <td>-0.025770</td>\n",
              "      <td>-1.922012</td>\n",
              "      <td>0.386764</td>\n",
              "      <td>-0.852154</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.002732</td>\n",
              "      <td>4</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>-0.911691</td>\n",
              "      <td>1.066427</td>\n",
              "      <td>0</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>-0.026547</td>\n",
              "      <td>-1.906459</td>\n",
              "      <td>1.140289</td>\n",
              "      <td>-0.852154</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.002732</td>\n",
              "      <td>2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>-0.814128</td>\n",
              "      <td>1.109280</td>\n",
              "      <td>0</td>\n",
              "      <td>0.506250</td>\n",
              "      <td>-0.023489</td>\n",
              "      <td>-1.890905</td>\n",
              "      <td>-0.891945</td>\n",
              "      <td>-0.852154</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.002732</td>\n",
              "      <td>4</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>-0.448755</td>\n",
              "      <td>-0.759942</td>\n",
              "      <td>1</td>\n",
              "      <td>0.549583</td>\n",
              "      <td>-0.026456</td>\n",
              "      <td>0.675480</td>\n",
              "      <td>-0.503766</td>\n",
              "      <td>-0.833245</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.002732</td>\n",
              "      <td>2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id  LATITUDE  LONGITUDE  STATE  DISCOVERY_TIME  ...  LABEL    0    1    2    3\n",
              "0   0  0.988292  -0.985738      1        0.054167  ...      1  1.0  0.0  0.0  0.0\n",
              "1   1 -0.401537   0.925104      0        0.464583  ...      4  0.0  0.0  0.0  1.0\n",
              "2   2 -0.911691   1.066427      0        0.666667  ...      2  0.0  1.0  0.0  0.0\n",
              "3   3 -0.814128   1.109280      0        0.506250  ...      4  0.0  0.0  0.0  1.0\n",
              "4   4 -0.448755  -0.759942      1        0.549583  ...      2  0.0  1.0  0.0  0.0\n",
              "\n",
              "[5 rows x 16 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cQ6prpG6JFDa"
      },
      "source": [
        "###Create the catgegory vs all data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DU7aunNBJNYB"
      },
      "source": [
        "#Make a copy for each label, set that labels value to 1, the rest to -1\r\n",
        "#To change the features being passed in, make a dataframe with the new features, and replace dfImp with it.\r\n",
        "\r\n",
        "oneData = dfImp.copy()\r\n",
        "oneData.loc[(oneData['LABEL'] != 1,\"LABEL\")] = -1\r\n",
        "#Make numpy arrays for regression\r\n",
        "oneY = oneData['LABEL'].to_numpy()\r\n",
        "oneData.drop('LABEL', axis=1)\r\n",
        "oneX = oneData.to_numpy()\r\n",
        "\r\n",
        "twoData = dfImp.copy()\r\n",
        "twoData.loc[(twoData['LABEL'] != 2,\"LABEL\")] = -1\r\n",
        "twoData.loc[(twoData['LABEL'] == 2,\"LABEL\")] = 1\r\n",
        "#Make numpy arrays for regression\r\n",
        "twoY = twoData['LABEL'].to_numpy()\r\n",
        "twoData.drop('LABEL', axis=1)\r\n",
        "twoX = twoData.to_numpy()\r\n",
        "\r\n",
        "threeData = dfImp.copy()\r\n",
        "threeData.loc[(threeData['LABEL'] != 3,\"LABEL\")] = -1\r\n",
        "threeData.loc[(threeData['LABEL'] == 3,\"LABEL\")] = 1\r\n",
        "threeY = threeData['LABEL'].to_numpy()\r\n",
        "threeData.drop('LABEL', axis=1)\r\n",
        "threeX = threeData.to_numpy()\r\n",
        "\r\n",
        "fourData = dfImp.copy()\r\n",
        "fourData.loc[(fourData['LABEL'] != 4,\"LABEL\")] = -1\r\n",
        "fourData.loc[(fourData['LABEL'] == 4,\"LABEL\")] = 1\r\n",
        "fourY = fourData['LABEL'].to_numpy()\r\n",
        "fourData.drop('LABEL', axis=1)\r\n",
        "fourX = fourData.to_numpy()"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GKR4Nr9MhR9O",
        "outputId": "58315f79-e2d1-41ac-be87-ee1ce4fcb1f3"
      },
      "source": [
        "len(oneX)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "285382"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q0SAJworLdWx"
      },
      "source": [
        "###Logistic Regression and Cross Validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LhJ9VquyLixA",
        "outputId": "a95fdd66-01f3-446e-8653-c127fb717443"
      },
      "source": [
        "#Regularization values to check via cross validation\r\n",
        "#This can be swapped with some other parameter, the approach will be the came\r\n",
        "numParams = 2\r\n",
        "Cs = np.logspace(-3,1,numParams)\r\n",
        "\r\n",
        "#Scores for in and out classification for each one vs all, determined using LogisticRegression.score()\r\n",
        "scoreIn = np.zeros((4,numParams))\r\n",
        "scoreOut = np.zeros((4,numParams))\r\n",
        "\r\n",
        "#Run cross validation for each parameter!\r\n",
        "num_folds = 10\r\n",
        "for run in range(numParams):\r\n",
        "\r\n",
        "    # Initialize kfold cross-validation object with 10 folds:\r\n",
        "    kf = KFold(n_splits=num_folds)\r\n",
        "\r\n",
        "    # Iterate through cross-validation folds for each model\r\n",
        "    for train_index, test_index in kf.split(oneX):\r\n",
        "        \r\n",
        "        \r\n",
        "        # Training and testing data points for this fold:\r\n",
        "        x_train, x_test = oneX[train_index], oneX[test_index]\r\n",
        "        y_train, y_test = oneY[train_index], oneY[test_index]\r\n",
        "\r\n",
        "        # Instantiate a Ridge regression object (with little regularization, can change this)\r\n",
        "        log = LogisticRegression(C = Cs[run])\r\n",
        "\r\n",
        "        #Perform the fitting\r\n",
        "        log.fit(x_train, y_train)\r\n",
        "\r\n",
        "        #Evaluate errors \r\n",
        "        scoreIn[0,run] += log.score(x_train, y_train)\r\n",
        "        scoreOut[0,run] += log.score(x_test, y_test)\r\n",
        "    # Iterate through cross-validation folds for each model\r\n",
        "    for train_index, test_index in kf.split(twoX):\r\n",
        "        \r\n",
        "        \r\n",
        "        # Training and testing data points for this fold:\r\n",
        "        x_train, x_test = twoX[train_index], twoX[test_index]\r\n",
        "        y_train, y_test = twoY[train_index], twoY[test_index]\r\n",
        "\r\n",
        "        # Instantiate a Ridge regression object (with little regularization, can change this)\r\n",
        "        log = LogisticRegression(C = Cs[run])\r\n",
        "\r\n",
        "        #Perform the fitting\r\n",
        "        log.fit(x_train, y_train)\r\n",
        "\r\n",
        "        #Evaluate errors \r\n",
        "        scoreIn[1,run] += log.score(x_train, y_train)\r\n",
        "        scoreOut[1,run] += log.score(x_test, y_test)\r\n",
        "    # Iterate through cross-validation folds for each model\r\n",
        "    for train_index, test_index in kf.split(threeX):\r\n",
        "        \r\n",
        "        \r\n",
        "        # Training and testing data points for this fold:\r\n",
        "        x_train, x_test = threeX[train_index], threeX[test_index]\r\n",
        "        y_train, y_test = threeY[train_index], threeY[test_index]\r\n",
        "\r\n",
        "        # Instantiate a Ridge regression object (with little regularization, can change this)\r\n",
        "        log = LogisticRegression(C = Cs[run])\r\n",
        "\r\n",
        "        #Perform the fitting\r\n",
        "        log.fit(x_train, y_train)\r\n",
        "\r\n",
        "        #Evaluate errors \r\n",
        "        scoreIn[2,run] += log.score(x_train, y_train)\r\n",
        "        scoreOut[2,run] += log.score(x_test, y_test)\r\n",
        "    # Iterate through cross-validation folds for each model\r\n",
        "    for train_index, test_index in kf.split(fourX):\r\n",
        "        \r\n",
        "        \r\n",
        "        # Training and testing data points for this fold:\r\n",
        "        x_train, x_test = fourX[train_index], fourX[test_index]\r\n",
        "        y_train, y_test = fourY[train_index], fourY[test_index]\r\n",
        "\r\n",
        "        # Instantiate a Ridge regression object (with little regularization, can change this)\r\n",
        "        log = LogisticRegression(C = Cs[run])\r\n",
        "\r\n",
        "        #Perform the fitting\r\n",
        "        log.fit(x_train, y_train)\r\n",
        "\r\n",
        "        #Evaluate errors \r\n",
        "        scoreIn[3,run] += log.score(x_train, y_train)\r\n",
        "        scoreOut[3,run] += log.score(x_test, y_test)\r\n",
        "\r\n",
        "scoreIn = scoreIn/num_folds\r\n",
        "scoreOut = scoreOut/num_folds\r\n",
        "\r\n",
        "print(\"Scores In\")\r\n",
        "print(scoreIn)\r\n",
        "print(\"Scores Out\")\r\n",
        "print(scoreOut)\r\n",
        "\r\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Scores In\n",
            "[[0.91292606 0.91292606]\n",
            " [0.6141896  0.61418882]\n",
            " [0.85103826 0.85103826]\n",
            " [0.81656867 0.81656867]]\n",
            "Scores Out\n",
            "[[0.91309556 0.91309556]\n",
            " [0.61018603 0.61018603]\n",
            " [0.85103846 0.85103846]\n",
            " [0.81656852 0.81656852]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vCgSXjEm0flf"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8EKNamEHpMVN"
      },
      "source": [
        "Output from first run when Cs was accidentally set to .1-10**10\r\n",
        "\r\n",
        "Scores In\r\n",
        "\r\n",
        "[[0.91292294 0.91292294 0.91292294 0.91292294 0.91292294 0.91292294\r\n",
        "  0.91292294 0.91292294 0.91292294 0.91292294 0.91292294 0.91292294\r\n",
        "  0.91292294 0.91292294 0.91292294 0.91292294 0.91292294 0.91292294\r\n",
        "  0.91292294 0.91292294]\r\n",
        "\r\n",
        " [0.6141896  0.6141896  0.6141896  0.6141896  0.6141896  0.6141896\r\n",
        "  0.6141896  0.6141896  0.6141896  0.6141896  0.6141896  0.6141896\r\n",
        "  0.6141896  0.6141896  0.6141896  0.6141896  0.6141896  0.6141896\r\n",
        "  0.6141896  0.6141896 ]\r\n",
        "\r\n",
        " [0.85103826 0.85103826 0.85103826 0.85103826 0.85103826 0.85103826\r\n",
        "  0.85103826 0.85103826 0.85103826 0.85103826 0.85103826 0.85103826\r\n",
        "  0.85103826 0.85103826 0.85103826 0.85103826 0.85103826 0.85103826\r\n",
        "  0.85103826 0.85103826]\r\n",
        " [0.81656867 0.81656867 0.81656867 0.81656867 0.81656867 0.81656867\r\n",
        "  0.81656867 0.81656867 0.81656867 0.81656867 0.81656867 0.81656867\r\n",
        "  0.81656867 0.81656867 0.81656867 0.81656867 0.81656867 0.81656867\r\n",
        "  0.81656867 0.81656867]]\r\n",
        "\r\n",
        "Scores Out\r\n",
        "\r\n",
        "[[0.91292294 0.91292294 0.91292294 0.91292294 0.91292294 0.91292294\r\n",
        "  0.91292294 0.91292294 0.91292294 0.91292294 0.91292294 0.91292294\r\n",
        "  0.91292294 0.91292294 0.91292294 0.91292294 0.91292294 0.91292294\r\n",
        "  0.91292294 0.91292294]\r\n",
        "\r\n",
        " [0.6141896  0.6141896  0.6141896  0.6141896  0.6141896  0.6141896\r\n",
        "  0.6141896  0.6141896  0.6141896  0.6141896  0.6141896  0.6141896\r\n",
        "  0.6141896  0.6141896  0.6141896  0.6141896  0.6141896  0.6141896\r\n",
        "  0.6141896  0.6141896 ]\r\n",
        "\r\n",
        " [0.85103826 0.85103826 0.85103826 0.85103826 0.85103826 0.85103826\r\n",
        "  0.85103826 0.85103826 0.85103826 0.85103826 0.85103826 0.85103826\r\n",
        "  0.85103826 0.85103826 0.85103826 0.85103826 0.85103826 0.85103826\r\n",
        "  0.85103826 0.85103826]\r\n",
        "\r\n",
        " [0.81656867 0.81656867 0.81656867 0.81656867 0.81656867 0.81656867\r\n",
        "  0.81656867 0.81656867 0.81656867 0.81656867 0.81656867 0.81656867\r\n",
        "  0.81656867 0.81656867 0.81656867 0.81656867 0.81656867 0.81656867\r\n",
        "  0.81656867 0.81656867]]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M-Cmjm-flPAk"
      },
      "source": [
        "#Make a copy for each label, set that labels value to 1, the rest to -1\r\n",
        "#To change the features being passed in, make a dataframe with the new features, and replace dfImp with it.\r\n",
        "\r\n",
        "featureDrop = dfImp.drop(['STATE','YEAR','FIPS_CODE','FIPS_NAME',\r\n",
        "                  'SOURCE_REPORTING_UNIT_NAME','id','0','1','2','3'], axis=1)\r\n",
        "\r\n",
        "\r\n",
        "oneData = featureDrop.copy()\r\n",
        "oneData.loc[(oneData['LABEL'] != 1,\"LABEL\")] = -1\r\n",
        "#Make numpy arrays for regression\r\n",
        "oneY = oneData['LABEL'].to_numpy()\r\n",
        "\r\n",
        "oneX = oneData.drop('LABEL', axis=1).to_numpy()\r\n",
        "#Add weights to address there being less of each example\r\n",
        "oneWeights = np.zeros(len(oneY))\r\n",
        "numOnes = len(np.where(oneY==1)[0])\r\n",
        "oneWeights[np.where(oneY==1)] = (len(oneY)-numOnes)/len(oneY)\r\n",
        "oneWeights[np.where(oneY!=1)] = numOnes/len(oneY)\r\n",
        "\r\n",
        "twoData = featureDrop.copy()\r\n",
        "twoData.loc[(twoData['LABEL'] != 2,\"LABEL\")] = -1\r\n",
        "twoData.loc[(twoData['LABEL'] == 2,\"LABEL\")] = 1\r\n",
        "#Make numpy arrays for regression\r\n",
        "twoY = twoData['LABEL'].to_numpy()\r\n",
        "\r\n",
        "twoX = twoData.drop('LABEL', axis=1).to_numpy()\r\n",
        "#Add weights to address there being less of each example\r\n",
        "twoWeights = np.zeros(len(twoY))\r\n",
        "numtwos = len(np.where(twoY==1)[0])\r\n",
        "twoWeights[np.where(twoY==1)] = (len(twoY)-numtwos)/len(twoY)\r\n",
        "twoWeights[np.where(twoY!=1)] = numtwos/len(twoY)\r\n",
        "\r\n",
        "threeData = featureDrop.copy()\r\n",
        "threeData.loc[(threeData['LABEL'] != 3,\"LABEL\")] = -1\r\n",
        "threeData.loc[(threeData['LABEL'] == 3,\"LABEL\")] = 1\r\n",
        "threeY = threeData['LABEL'].to_numpy()\r\n",
        "\r\n",
        "threeX = threeData.drop('LABEL', axis=1).to_numpy()\r\n",
        "#Add weights to address there being less of each example\r\n",
        "threeWeights = np.zeros(len(threeY))\r\n",
        "numthrees = len(np.where(threeY==1)[0])\r\n",
        "threeWeights[np.where(threeY==1)] = (len(threeY)-numthrees)/len(threeY)\r\n",
        "threeWeights[np.where(threeY!=1)] = numthrees/len(threeY)\r\n",
        "\r\n",
        "fourData = featureDrop.copy()\r\n",
        "fourData.loc[(fourData['LABEL'] != 4,\"LABEL\")] = -1\r\n",
        "fourData.loc[(fourData['LABEL'] == 4,\"LABEL\")] = 1\r\n",
        "fourY = fourData['LABEL'].to_numpy()\r\n",
        "\r\n",
        "fourX = fourData.drop('LABEL', axis=1).to_numpy()\r\n",
        "#Add weights to address there being less of each example\r\n",
        "fourWeights = np.zeros(len(fourY))\r\n",
        "numfours = len(np.where(fourY==1)[0])\r\n",
        "fourWeights[np.where(fourY==1)] = (len(fourY)-numfours)/len(fourY)\r\n",
        "fourWeights[np.where(fourY!=1)] = numfours/len(fourY)"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sB-EvEi0pAbd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "010be9a5-aa4b-474e-dc89-4ea1c1a9e910"
      },
      "source": [
        "#Regularization values to check via cross validation\r\n",
        "#This can be swapped with some other parameter, the approach will be the came\r\n",
        "numParams = 11\r\n",
        "Cs = np.logspace(-10,1,numParams)\r\n",
        "\r\n",
        "#Scores for in and out classification for each one vs all, determined using LogisticRegression.score()\r\n",
        "scoreIn = np.zeros((4,numParams))\r\n",
        "scoreOut = np.zeros((4,numParams))\r\n",
        "\r\n",
        "#Run cross validation for each parameter!\r\n",
        "num_folds = 10\r\n",
        "for run in range(numParams):\r\n",
        "\r\n",
        "    # Initialize kfold cross-validation object with 10 folds:\r\n",
        "    kf = KFold(n_splits=num_folds)\r\n",
        "\r\n",
        "    # Iterate through cross-validation folds for each model\r\n",
        "    for train_index, test_index in kf.split(oneX):\r\n",
        "        \r\n",
        "        \r\n",
        "        # Training and testing data points for this fold:\r\n",
        "        x_train, x_test = oneX[train_index], oneX[test_index]\r\n",
        "        y_train, y_test = oneY[train_index], oneY[test_index]\r\n",
        "        weights = oneWeights[train_index]\r\n",
        "\r\n",
        "        # Instantiate a Ridge regression object (with little regularization, can change this)\r\n",
        "        log = LogisticRegression(C = Cs[run])\r\n",
        "\r\n",
        "        #Perform the fitting\r\n",
        "        log.fit(x_train, y_train,weights)\r\n",
        "\r\n",
        "        #Evaluate errors \r\n",
        "        scoreIn[0,run] += log.score(x_train, y_train)\r\n",
        "        scoreOut[0,run] += log.score(x_test, y_test)\r\n",
        "    # Iterate through cross-validation folds for each model\r\n",
        "    for train_index, test_index in kf.split(twoX):\r\n",
        "        \r\n",
        "        \r\n",
        "        # Training and testing data points for this fold:\r\n",
        "        x_train, x_test = twoX[train_index], twoX[test_index]\r\n",
        "        y_train, y_test = twoY[train_index], twoY[test_index]\r\n",
        "        weights = twoWeights[train_index]\r\n",
        "\r\n",
        "        # Instantiate a Ridge regression object (with little regularization, can change this)\r\n",
        "        log = LogisticRegression(C = Cs[run])\r\n",
        "\r\n",
        "        #Perform the fitting\r\n",
        "        log.fit(x_train, y_train,weights)\r\n",
        "\r\n",
        "        #Evaluate errors \r\n",
        "        scoreIn[1,run] += log.score(x_train, y_train)\r\n",
        "        scoreOut[1,run] += log.score(x_test, y_test)\r\n",
        "    # Iterate through cross-validation folds for each model\r\n",
        "    for train_index, test_index in kf.split(threeX):\r\n",
        "        \r\n",
        "        \r\n",
        "        # Training and testing data points for this fold:\r\n",
        "        x_train, x_test = threeX[train_index], threeX[test_index]\r\n",
        "        y_train, y_test = threeY[train_index], threeY[test_index]\r\n",
        "        weights = threeWeights[train_index]\r\n",
        "\r\n",
        "        # Instantiate a Ridge regression object (with little regularization, can change this)\r\n",
        "        log = LogisticRegression(C = Cs[run])\r\n",
        "\r\n",
        "        #Perform the fitting\r\n",
        "        log.fit(x_train, y_train,weights)\r\n",
        "\r\n",
        "        #Evaluate errors \r\n",
        "        scoreIn[2,run] += log.score(x_train, y_train)\r\n",
        "        scoreOut[2,run] += log.score(x_test, y_test)\r\n",
        "    # Iterate through cross-validation folds for each model\r\n",
        "    for train_index, test_index in kf.split(fourX):\r\n",
        "        \r\n",
        "        \r\n",
        "        # Training and testing data points for this fold:\r\n",
        "        x_train, x_test = fourX[train_index], fourX[test_index]\r\n",
        "        y_train, y_test = fourY[train_index], fourY[test_index]\r\n",
        "        weights = fourWeights[train_index]\r\n",
        "\r\n",
        "        # Instantiate a Ridge regression object (with little regularization, can change this)\r\n",
        "        log = LogisticRegression(C = Cs[run])\r\n",
        "\r\n",
        "        #Perform the fitting\r\n",
        "        log.fit(x_train, y_train,weights)\r\n",
        "\r\n",
        "        #Evaluate errors \r\n",
        "        scoreIn[3,run] += log.score(x_train, y_train)\r\n",
        "        scoreOut[3,run] += log.score(x_test, y_test)\r\n",
        "\r\n",
        "scoreIn = scoreIn/num_folds\r\n",
        "scoreOut = scoreOut/num_folds\r\n",
        "\r\n",
        "print(\"Scores In\")\r\n",
        "print(scoreIn)\r\n",
        "print(\"Scores Out\")\r\n",
        "print(scoreOut)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Scores In\n",
            "[[0.58237841 0.58237841 0.58237841 0.56269175 0.65230429 0.65288397\n",
            "  0.66918454 0.68907873 0.67906214 0.6769558  0.67675918]\n",
            " [0.47600372 0.47600372 0.47600372 0.51096742 0.62562694 0.62710761\n",
            "  0.62691956 0.62714654 0.62716289 0.62717574 0.62717691]\n",
            " [0.43122935 0.43122935 0.43122935 0.40198124 0.56194138 0.54580137\n",
            "  0.54578191 0.54574103 0.54557672 0.54553584 0.54553078]\n",
            " [0.37710142 0.35615991 0.3561603  0.36784522 0.64047719 0.60830201\n",
            "  0.60778185 0.60852783 0.60968924 0.60982901 0.60984264]]\n",
            "Scores Out\n",
            "[[0.56512737 0.56512737 0.56512737 0.53952291 0.65353758 0.65259537\n",
            "  0.66935889 0.68702992 0.6758834  0.67354617 0.6733955 ]\n",
            " [0.43247269 0.43247269 0.43247269 0.46540032 0.62015848 0.62587365\n",
            "  0.62670061 0.62681975 0.62679873 0.62677069 0.6267742 ]\n",
            " [0.41685947 0.41685947 0.41685947 0.37485933 0.53625817 0.54579096\n",
            "  0.54575592 0.54567883 0.54550012 0.54546859 0.54546508]\n",
            " [0.33981244 0.31949917 0.31949917 0.32998344 0.62132189 0.6079117\n",
            "  0.60778205 0.60851791 0.60947803 0.60962521 0.60964623]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TR6vgMHuszAC"
      },
      "source": [
        "Test accuracy from all features (no regularization)\r\n",
        "\r\n",
        "[0.9794988397444669 0.7435116823214506 0.8662798073711897 0.8165686675754158]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e0sJ2FzU07uG",
        "outputId": "a012ab64-4cb0-4bb3-82ca-af359f3308f1"
      },
      "source": [
        "#Best regularization for each parameter\r\n",
        "print(np.max(scoreIn[0]),np.max(scoreIn[1]),np.max(scoreIn[2]),np.max(scoreIn[3]))\r\n",
        "print(np.argmax(scoreIn,axis=1))"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.6890787304764945 0.6271769098652454 0.5619413762612553 0.6404771853699696\n",
            "[ 7 10  4  4]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ge7hFEbjvNgh",
        "outputId": "fcaf7c9e-bdf5-4cc4-a1b4-673dce0ff661"
      },
      "source": [
        "#Build model using the regularization (note we take for the 4th label c = 8 as regularization didn't have an effect so less is better)\r\n",
        "Cs = np.logspace(-10,1,numParams)\r\n",
        "model = [LogisticRegression(C = Cs[7]),LogisticRegression(C = Cs[10]),LogisticRegression(C = Cs[4]),LogisticRegression(C = Cs[4])]\r\n",
        "model[0].fit(oneX, oneY,oneWeights)\r\n",
        "print(1)\r\n",
        "model[1].fit(twoX, twoY,twoWeights)\r\n",
        "print(2)\r\n",
        "model[2].fit(threeX, threeY,threeWeights)\r\n",
        "print(3)\r\n",
        "model[3].fit(fourX, fourY,fourWeights)\r\n",
        "print(4)\r\n",
        "\r\n",
        "#Print statements are so we can see where errors are in converging (if any).\r\n",
        "#Seems to be on the lightning model, which has the best performance oddly\r\n"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1\n",
            "2\n",
            "3\n",
            "4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2o_4lvpZwCqB",
        "outputId": "092a9165-d1a8-4d33-956f-05bef86f719d"
      },
      "source": [
        "#Checking prediction works as we think\r\n",
        "#Take random point\r\n",
        "testPoints = oneX[0:20,:]\r\n",
        "model[1].predict_proba(testPoints),model[1].predict(testPoints),twoY[0:20]\r\n",
        "\r\n",
        "#testPositives = oneX[np.where(oneY == 1)]\r\n",
        "\r\n",
        "#print(model[0].predict_proba(testPositives[0:50]))"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[0.58207108, 0.41792892],\n",
              "        [0.35199495, 0.64800505],\n",
              "        [0.3177252 , 0.6822748 ],\n",
              "        [0.31928425, 0.68071575],\n",
              "        [0.48945935, 0.51054065],\n",
              "        [0.48370951, 0.51629049],\n",
              "        [0.31021619, 0.68978381],\n",
              "        [0.36150242, 0.63849758],\n",
              "        [0.31980787, 0.68019213],\n",
              "        [0.31888225, 0.68111775],\n",
              "        [0.32316931, 0.67683069],\n",
              "        [0.31772451, 0.68227549],\n",
              "        [0.31517959, 0.68482041],\n",
              "        [0.30856732, 0.69143268],\n",
              "        [0.32386431, 0.67613569],\n",
              "        [0.32421653, 0.67578347],\n",
              "        [0.35796472, 0.64203528],\n",
              "        [0.30869116, 0.69130884],\n",
              "        [0.32323209, 0.67676791],\n",
              "        [0.35454336, 0.64545664]]),\n",
              " array([-1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
              "         1,  1,  1]),\n",
              " array([-1, -1,  1, -1,  1,  1, -1, -1, -1, -1,  1,  1, -1,  1, -1,  1, -1,\n",
              "         1,  1, -1]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1LVhr99fY-TW",
        "outputId": "a8a7f274-8feb-4619-d0b7-62da9a3b2d73"
      },
      "source": [
        "#Testing model\r\n",
        "\r\n",
        "#Predictions \r\n",
        "predictions = np.zeros((len(oneX),4))\r\n",
        "\r\n",
        "#Predict the probabilities for each point\r\n",
        "for i in range(4):\r\n",
        "    predictions[:,i] = model[i].predict_proba(oneX)[:,1]\r\n",
        "\r\n",
        "#Normalize each row\r\n",
        "predictions = predictions / np.linalg.norm(predictions, axis=1,ord=1).reshape(len(oneY),1)\r\n",
        "\r\n",
        "#Score\r\n",
        "trainAUC = roc_auc_score(featureDrop['LABEL'].to_numpy(), predictions, multi_class='ovr')\r\n",
        "trainAUC"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6366257661720174"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "Hm294p7Ltevp",
        "outputId": "be54ee3c-68c6-409f-d355-df2a18ff8f5f"
      },
      "source": [
        "#Now running on the test data to predict\r\n",
        "#Use the imputed and normalized data (This link will need to be updated when we merge the branches)\r\n",
        "dfTest = pd.read_csv('https://raw.githubusercontent.com/treyra/CS155_miniproject/data_visualization_v1/data_cleanup/testdata_imputed_normalized_minmax.csv',sep=',', header=0,index_col=0)\r\n",
        "\r\n",
        "dfTest.head()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>LATITUDE</th>\n",
              "      <th>LONGITUDE</th>\n",
              "      <th>STATE</th>\n",
              "      <th>DISCOVERY_TIME</th>\n",
              "      <th>FIRE_SIZE</th>\n",
              "      <th>FIPS_NAME</th>\n",
              "      <th>FIPS_CODE</th>\n",
              "      <th>SOURCE_REPORTING_UNIT_NAME</th>\n",
              "      <th>YEAR</th>\n",
              "      <th>DAY</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>285382</td>\n",
              "      <td>-0.232600</td>\n",
              "      <td>-0.828839</td>\n",
              "      <td>1</td>\n",
              "      <td>0.66875</td>\n",
              "      <td>-0.026456</td>\n",
              "      <td>0.768803</td>\n",
              "      <td>-0.435263</td>\n",
              "      <td>-0.303789</td>\n",
              "      <td>1.058824</td>\n",
              "      <td>0.002732</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>285383</td>\n",
              "      <td>-0.335939</td>\n",
              "      <td>-0.760377</td>\n",
              "      <td>1</td>\n",
              "      <td>0.64375</td>\n",
              "      <td>-0.026526</td>\n",
              "      <td>0.784357</td>\n",
              "      <td>-0.435263</td>\n",
              "      <td>0.320212</td>\n",
              "      <td>1.058824</td>\n",
              "      <td>0.002732</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>285384</td>\n",
              "      <td>0.945131</td>\n",
              "      <td>-0.982574</td>\n",
              "      <td>1</td>\n",
              "      <td>0.50000</td>\n",
              "      <td>-0.026526</td>\n",
              "      <td>0.628819</td>\n",
              "      <td>-0.001415</td>\n",
              "      <td>-0.871063</td>\n",
              "      <td>1.058824</td>\n",
              "      <td>0.002732</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>285385</td>\n",
              "      <td>-0.817080</td>\n",
              "      <td>0.998962</td>\n",
              "      <td>2</td>\n",
              "      <td>0.87500</td>\n",
              "      <td>-0.026314</td>\n",
              "      <td>-1.579828</td>\n",
              "      <td>0.500935</td>\n",
              "      <td>2.419125</td>\n",
              "      <td>1.058824</td>\n",
              "      <td>0.005464</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>285386</td>\n",
              "      <td>-0.682598</td>\n",
              "      <td>-0.695973</td>\n",
              "      <td>1</td>\n",
              "      <td>0.05250</td>\n",
              "      <td>-0.026526</td>\n",
              "      <td>1.204311</td>\n",
              "      <td>-0.960447</td>\n",
              "      <td>-0.681972</td>\n",
              "      <td>1.058824</td>\n",
              "      <td>0.005464</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       id  LATITUDE  LONGITUDE  ...  SOURCE_REPORTING_UNIT_NAME      YEAR       DAY\n",
              "0  285382 -0.232600  -0.828839  ...                   -0.303789  1.058824  0.002732\n",
              "1  285383 -0.335939  -0.760377  ...                    0.320212  1.058824  0.002732\n",
              "2  285384  0.945131  -0.982574  ...                   -0.871063  1.058824  0.002732\n",
              "3  285385 -0.817080   0.998962  ...                    2.419125  1.058824  0.005464\n",
              "4  285386 -0.682598  -0.695973  ...                   -0.681972  1.058824  0.005464\n",
              "\n",
              "[5 rows x 11 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XVncSpwlvMJB"
      },
      "source": [
        "testDrop = dfTest.drop(['STATE','YEAR','FIPS_CODE','FIPS_NAME',\r\n",
        "                  'SOURCE_REPORTING_UNIT_NAME','id'], axis=1)\r\n",
        "testX = testDrop.to_numpy()"
      ],
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b6zNam5Swtx4"
      },
      "source": [
        "#Predictions on test data\r\n",
        "\r\n",
        "#Predictions \r\n",
        "\r\n",
        "predictionsTest = np.zeros((len(testX),4))\r\n",
        "\r\n",
        "#Predict the probabilities for each point\r\n",
        "for i in range(4):\r\n",
        "    predictionsTest[:,i] = model[i].predict_proba(testX)[:,1]\r\n",
        "\r\n",
        "#Normalize each row\r\n",
        "predictionsTest = predictionsTest / np.linalg.norm(predictionsTest, axis=1,ord=1).reshape(len(testX),1)\r\n",
        "\r\n",
        "#Add id\r\n",
        "ids = np.zeros((len(testX),1))\r\n",
        "ids[:,0] = dfTest[\"id\"].to_numpy()\r\n",
        "predictionsTest = np.hstack((ids,predictionsTest))\r\n",
        "#Save to a csv\r\n",
        "predictionsTest.tofile('WILDFIRES_TEST.csv', sep = ',')"
      ],
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HZP60apkdHRy",
        "outputId": "0c17ffd9-8302-4b78-a377-0ef667e6fa8c"
      },
      "source": [
        "from google.colab import drive\r\n",
        "drive.mount('drive')\r\n",
        "#Save to a csv"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at drive; to attempt to forcibly remount, call drive.mount(\"drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p0HciIVweKiB"
      },
      "source": [
        "df = pd.DataFrame(predictionsTest)\r\n",
        "df.to_csv('WILDFIRES_TEST.csv', sep = ',')\r\n",
        "!cp WILDFIRES_TEST.csv \"drive/My Drive/\""
      ],
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "f3vHMxurel6J",
        "outputId": "a09b8c44-e165-4900-9016-2e8a3f253eb0"
      },
      "source": [
        "df"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>285382.0</td>\n",
              "      <td>0.146393</td>\n",
              "      <td>0.282179</td>\n",
              "      <td>0.284065</td>\n",
              "      <td>0.287363</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>285383.0</td>\n",
              "      <td>0.138295</td>\n",
              "      <td>0.289212</td>\n",
              "      <td>0.285035</td>\n",
              "      <td>0.287458</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>285384.0</td>\n",
              "      <td>0.239881</td>\n",
              "      <td>0.224618</td>\n",
              "      <td>0.263572</td>\n",
              "      <td>0.271930</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>285385.0</td>\n",
              "      <td>0.118297</td>\n",
              "      <td>0.357493</td>\n",
              "      <td>0.267693</td>\n",
              "      <td>0.256518</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>285386.0</td>\n",
              "      <td>0.102760</td>\n",
              "      <td>0.309488</td>\n",
              "      <td>0.293493</td>\n",
              "      <td>0.294259</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>73030</th>\n",
              "      <td>358412.0</td>\n",
              "      <td>0.190476</td>\n",
              "      <td>0.305899</td>\n",
              "      <td>0.257590</td>\n",
              "      <td>0.246034</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>73031</th>\n",
              "      <td>358413.0</td>\n",
              "      <td>0.219848</td>\n",
              "      <td>0.232088</td>\n",
              "      <td>0.273195</td>\n",
              "      <td>0.274869</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>73032</th>\n",
              "      <td>358414.0</td>\n",
              "      <td>0.281112</td>\n",
              "      <td>0.194960</td>\n",
              "      <td>0.259296</td>\n",
              "      <td>0.264633</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>73033</th>\n",
              "      <td>358415.0</td>\n",
              "      <td>0.316674</td>\n",
              "      <td>0.178080</td>\n",
              "      <td>0.249360</td>\n",
              "      <td>0.255886</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>73034</th>\n",
              "      <td>358416.0</td>\n",
              "      <td>0.369093</td>\n",
              "      <td>0.148829</td>\n",
              "      <td>0.236360</td>\n",
              "      <td>0.245717</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>73035 rows × 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "              0         1         2         3         4\n",
              "0      285382.0  0.146393  0.282179  0.284065  0.287363\n",
              "1      285383.0  0.138295  0.289212  0.285035  0.287458\n",
              "2      285384.0  0.239881  0.224618  0.263572  0.271930\n",
              "3      285385.0  0.118297  0.357493  0.267693  0.256518\n",
              "4      285386.0  0.102760  0.309488  0.293493  0.294259\n",
              "...         ...       ...       ...       ...       ...\n",
              "73030  358412.0  0.190476  0.305899  0.257590  0.246034\n",
              "73031  358413.0  0.219848  0.232088  0.273195  0.274869\n",
              "73032  358414.0  0.281112  0.194960  0.259296  0.264633\n",
              "73033  358415.0  0.316674  0.178080  0.249360  0.255886\n",
              "73034  358416.0  0.369093  0.148829  0.236360  0.245717\n",
              "\n",
              "[73035 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SQtitcEie4Zx"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}